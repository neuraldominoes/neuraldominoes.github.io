---
title: "AGT Notes: Week - 1"
date: 2025-05-19
math: true  
tags: [algo-game-theory]
---

# ISP Routing Game


Two ISPs, say 1 and 2, 
- The first type of traffic  from node source 1 belonging to ISP 1 and is targeted towards node destination 1 belonging to ISP B. 
- The second type of traffic from node source 2 belonging to ISP 2 and destined towards node destination 2 belonging to ISP 1.
-  C and NC are peering points. Traffic between the two ISP networks can only flow either through C or NC.

 - Cost for source 1/source2 to C = 1
 - Cost for NC to dest 1/dest 2 = 1
 - Cost for source 1 to NC / source 2 to NC = 3


This is pretty analogous to prisoners' choices in PD. One is *"selfish"*, i.e. it is better for the player themself but hurts other player,  The cost matrix is analogous to the one for PD. 



# Pollution Game 

- Each country has the choice to PASS rule "CONTROL POLLUTION" or NOT PASS.
- Cost for a country to control its pollution: 3
- If a country doesn't control pollution, i.e. it pollutes, it adds 1 to the cost of every country, including itself (say, health costs because of pollution, etc.)
- So, of *n* countries, if *k* don't control pollution and *n-k* control pollution, then:
    - cost for each pollution controlling country is : (3) + (*k*) x 1 = *k* + 3
    - cost for each country that pollutes = k
 
 $\therefore$ The only stable solution would be no country controlling their pollution. 
 >(Otherwise countries controlling pollution would be tempted to switch to not control to improve their payoff)
 > If they all controlled pollution, on the other hand, the cost would have been just 3 for each country.


# Tragedy Of The Commons 

 - n players using a shared channel with max capacity=1. Channel's quality detetoriates as the more of the channel's capacity is used by everyone. Player $i$ can choose some $x_i \in [0,1]$ where $x_i$ is the fraction of the channel they want to use for transferring their info. 
 - if $\sum_{i}x_i$ >1, all players get nothing 
 - if $\sum_{i}x_i$ <1, then each player will get a benefit value = $x_i(1-\sum_{i}x_i)$ 
 -  Look at single player $i$. Let $x_i = x$,  $\sum_{j \neq  i}x_i$ <1, and $\sum_{j \neq  i}x_i = c$. 
 - The payoff of player $i$ is $x(1 - c - x)$. To get max payoff for player $i$, put $\frac{d}{dx} \left( x(1 - c - x) \right) = 0 \implies x = \frac{1 - c}{2}$
 - We want a stable set of strategies . All players are playing this optimal selfish strategy given the strategies of all other players. 
 - So $x = (1 - c)/2 = (1-(n-1)x)/2 \implies x = 1/(n+1)$. So payoff for each player will come to be $1/(n+1)^2$. 
 - Total payoff for all players is = $n$ x $1/(n+1)^2$  so approximately $1/n$
 - On the other hand, say the total bandwidth used ($\sum_{i}x_i$) = 1/2 , then sum of payoffs of all players comes to be 1/4, which is around ($n/4$) x (the sum of payoffs in the stable situation), which is a considerable larger total payoff value. 
 - Aaand that's why the solution is a "tragedy" :( ---> the players sharing the resource *overuse* the resource so the *total value of the shared resource gets dramatically decreased*. (sort of like the pollution game)


# Coordination Games 

- Multiple outcomes can be stable.
- A simple coordination game : two players choosing b/w two options, with both wanting to choose the *same*

## The Battle of The Sexes 

- B- prefers baseball , G- prefers softball, Would prefer to spend evening together rather than separately. 

- Both attending baseball (or) Both attending softball ARE stable solutions. 

- This is because if one of them tried to improve their payoff given that the other player kept their choice, the payoff would only reduce for them. 


![image](https://github.com/user-attachments/assets/fe021418-e712-42aa-a38f-36dbd185c9cf)

## Routing Congestion Game 

- Two streams of traffic from O, can go to the rest of the network through A or B. 
- A is closer than B.
- But these points (A,B) can get "congested" if too much traffic is sent through them, causing extra delay. 
- $\therefore$ Good soln. = two players coordinate and send traffic 1 and traffic 2 through different connection points. 
- Each player has 2 strategies: Route through A (or) Route through B

![image-1](https://github.com/user-attachments/assets/23c127ab-f8d8-483e-8454-b25988f5a69d)

# Randomized Mixed Strategies 

 Not ALL games have " stable solutions" (outcomes in which none of the players would like to deviate from the outcome)

## Matching pennies

- In the game of **matching pennies**, each player has a penny and must secretly turn the penny to either heads or tails.
- If the pennies match—both heads or both tails—player A keeps both pennies so he wins one from player B
- If the pennies do not match—one heads and one tails—B keeps both pennies, so she wins one from A.
- [https://math.ucr.edu/home/baez/games/games_13.html]

![image-4](https://github.com/user-attachments/assets/08d3d6ef-bc5b-4f87-9568-bfc40ba3319a)



## Simultaneous Move Game 
- Set  of $n$ players 
- Each player $i$ has own set of poss. strategies : $S_i$
- Each player $i$ selects strategy $s_i$ from $S_i$
- $s = (s_1, s_2,....s_n)$ - vector of strategies selected by all players 
- Each strategy vector will correspond to a certain outcome for a given player $i$, hence we will refer to the different strategy vectors w.r.t. a given player as "outcomes"
- given 2 outcomes $S_1$, $S_2 \in S$, $i$ weakly prefers $S_1$ to $S_2$ if $i$  prefers $S_1$ to $S_2$  or considers both equally good outcomes.
- Preference: Specifying a preference ordering on the outcomes - a complete, transitive, reflexive binary relation on all elts. of $S$ 
- Simplest way to specify "preferences" ? - Assign a value to each outcome  ("payoff" or "cost":)  )
- Payoff/Cost calculating funcns. : $u_i$ : $S$-> $R$  and $u_i$ : $S$-> $R$ , and $u_i(s) = - c_i(s)$ 

> Note that these cost/payoff calculating funcns. are a function of $s$ and not $s_i$, in which case it would mean that a player's payoff only depended on their own strategy and we would have $n$ separate optimization problems on our hands in that case. 
> This isn't a game. In a *game* the payoff of each player depends on the strategies of everyone else as well as his. 

## Representation of Games

- How do we specify games? 
- One way is to list all poss. strategies as well as the preferences of all the players. This is called the standard form or matrix form of a game 
- While this is good for 2 player games with few strategies, it gets very complicated with more players, more possible strategies (large or infinite strategy sets), etc. 
- We can avoid this by trying to narrow down the factors on which the payoffs depend on. 
- For example, in **The Pollution Game**, we can see that we do not need to list such a large size of input to represent the game ( that would mean listing all $2^n$ strategy vectors !) Instead we may observe that the payoff only depends on the *number* of players selecting a given strategy, and this greatly reduces the input needed to describe the game. 
- Other such ways: payoff may depend on strategies of a few players and not all players
- Such ways of representation -> compact representation.

# Solution concepts 

## Dominant Strategy Solution

- For a strategy vector $s \in S$, $s_i$ = strategy played by player $i$, $s_{-i}$ = $n-1$ dimensional vec. of strategies by all other players 
- $u_i(s)$= utility (cost/payoff) for player $i$
- $s \in S$ is a dominant strategy soln. if for each player $i$ and each alternate strat. vec.: $s\' \in S$, $u\_i(s\_i,s\'\_{-i}) \geq u\_i(s\'\_i,s\'\_{-i})$
- "Given any strategy vector, I can always increase (or keep same) my payoff by switching from my current one to my dominant strategy while everyone else's strategies stay the same"
> *Note*: A dominant strategy solution DOES NOT necessarily give optimal payoff to any of the players. Eg. Think about **The Pollution Game** or **Prisoner's Dilemma**
- Having a single dom. strat. for each player is usually satisfied by a very few games. Mechanism design aims to design games that have dom. strat. solns.  AND that have this soln. leading to some form of desirable outcome. (selfish behaviour-> leads to socially optimal outcome)

## Vickrey Auctions 

- Say, design an auction to sell a valuable painting. 
- Let each player (bidder) $i$ have value $v_i$ for the painting and the cost they will bid = $p$. Then the payoff for winning is $v_i - p$ and the payoff for not winning = 0. 
- Strategy of each player = his bid $p$ 
- While an obvious way might seem to just give the painting to the highest bidder, at the cost of their bid. But this will not have a dominant strategy solution. More on this here. ( NOTE: LINK THIS )
- How the Vickrey Auction works is by giving the hughest bidder the painting at the price of the SECOND highest bid. 
- Why is it useful designing it this way? Turns out that each players dominant strategy is to report his true value (valuation of the object $v_i$) as his bid, regardless of other players' bids. 
- Note 1: Even if player's true value is high: he will be in no danger of overpaying if he reports it, as he pays no more than the second highest bid. What is overpaying? Paying significantly more than the second highest bid. 
- Note 2: This format leads to painting being awarded to who values it the most. This is a socially optimal outcome 
-  Simple for players to play. Each player's optimal strategy is independent of other players' choices. "Revelation Principle", so the players simply say the truth and the game designer plays for them. 
- Problems with direct revelation: valuation functions can be very long and complex so communicating valuations may be a problem, assumes the existence of a *central trusted party* (we can try to use cryptograohic techniques to avoid this )

We see in the Vickrey Auction, that there does exist a single dominant strategy, where every player reports the max. money they would pay for the good, i.e. their true valuation of the good. 

> To recall, why is this a dominant strategy again: because given any strategy vector, he would be better off or the same: player $i$ increasing his bid to $v_i$ ( he obviously could not have bid more than $v_i$ ) will either mean he will manage to win or still not get the item anyway.

However, most games rarely have dominant strategy solutions. 
Instead we will try look for another kind of game theoretic solution in which the individual players try to maximize their payoffs. This idea is best captured by the notion of a Nash Equilibrium. 

## Pure Strategy Nash Equilibrium
- "Stable solution", like one in the Tragedy of Commons or the Battle Of The Sexes - No player can improve his payoff by deviating
- $s \in S$ is Nash Equilibrium if $\forall$ players i and for every other alternate strategy $s\'\_i \in S_i$, 
$u_i(s_i,s_{-i}) \geq u_i(s\'\_i,s_{-i})$
- i.e. No player $i$ can change $s_i$ -> $s'_i$ and improve payoff assuming that other players stick to strategies that they have chosen in $s$. 
- This solution is "self-enforcing". Oncr all players find themselves playing such a solution, no player has any incentive to sietch his strategy. 
- Any dominant strategy soln. is a Nash equilibrium (see that dominant strategy soln. is much "*stronger*" than Nash equilibrium)
- "Strictly dominant strategy soln." -> switching to $s_i$ will *strictly* improve the outcome. If exists, then this will be the *unique* Nash eq. for the game 
- Nash Equilibria, in general, need not be unique (coord. games have multiple) AND need not be optimal for the players (recall also that dom. strat. solns. need not be optimal for players)

> When there are multiple equilibria, different solutions can have different payoffs for players.

## Huh..?
> At this point, you might be saying, "Well, this is getting stranger and stranger. First you say it's self enforcing. Then you say that there could be multiple. How are you even supposed to predict what players will play and which equilibrium you'd expect them to play? How do they even know which equilibrium to coordinate on?"
And to that we say, well let's just be thankful for now that atleast it's a stable solution. Once proposed, no player will want to deviate.

## Mixed Strategy Nash Equil. 
- Games needn't necessarily have any pure strategy Nash equil. (like the Matching Pennies Game) 
- In the Matching Pennies Game, if each player plays H and T uniformly with a probability of 1/2 respectively, this is a stable solution. (you can see why, by recalling the defn. of a Nash equilibrium. Expected payoff remains 0 no matter what you'd change your probability distrib. to, given that the other player keeps playing (0.5,0.5))
- To define it more formally, players are allowed to pick a probability distribution over their set of available strategies - this is a "mixed strategy"
- Also  assume that while playing mixed Nash equilibria: players are risk neutral, and only want to maximize EXPECTED PAYOFF
- Independent distributions for each $s_i$ gives us an overall probability distribution over ALL strategy vectors $s$

## (Nash, 1951) *very famous :-)*

Any game with a finite set of players and a finite set of strategies has a Nash equilibrium of mixed strategies.


## Note: 
Games with infinite players, or an infinite strategy set, need not have Nash equilibria.



##  Pricing Game 

 - Two sellers compete to sell a product to three buyers (A, B, C). 
- Buyers A and C can only buy from Seller 1 and Seller 2, respectively, while Buyer B chooses the cheaper seller (or Seller 1 if prices are equal). 
- All buyers will pay up to $1. 
- Sellers set a single price in [0,1] and aim to maximize their total revenue (assume no production costs and their revenue is the full price of the product they sell). 
- **Strategies:** Sellers choose any price between $0 and $1 (uncountably many options). Now we will in fact, come to see that this is a game with no Nash Equilibria.
- **No Pure Nash Equilibrium:** If Seller 1 prices >$0.5, Seller 2 can undercut to earn more, triggering a cycle of undercutting. If Seller 1 prices ≤$0.5, Seller 2’s best move is to charge $1 (monopolizing Buyer C), but then Seller 1 can raise their price.
- **Mixed Strategy Equilibrium:** This is a bit harder to argue, so let's accept this for now. 
- The game lacks any Nash equilibrium, pure or mixed.
- **Intuition:** The competition for Buyer B destabilizes pricing, making it impossible for sellers to settle on a stable strategy.

  
![image-5](https://github.com/user-attachments/assets/fd056b05-297f-460c-9d94-b775e0ac6ab6)


---
## Stop Or Go

Imagine the scenario of two cars coming along different roads towards an intersection. As they approach the point where the two roads meet, they notice each other. Each one now has two choices: to either '_Go_'  (i.e. continue driving) or '_Stop_' (i.e. hit the brakes).

             **Go**           **Stop**

    **Go**      -10, -10      4, -1

   **Stop**     -1, 4       -3, -3

We have two possible pure strategy Nash equilibria now, scenarios in whcih one player "goes" and one "stops". 
               

For the above, though, we could also have a "traffic light" that randomly let one of the two players to cross with any probability. And here is where we segue into the concept of correlated equilibria. 




# Correlated Equilibria 

Using this assumes an "external correlation device", like in the case of the Stop or Go game,  a traffic light as described above.
A correlated eq. is a probability distribution over our set of strategy vectors. Eg. The traffic light picks "A goes B stops " with a probability 0.6 and "B goes A stops" with a probability 0.4. This forms a proability distribution (0.6, 0.4, 0, 0) over our strategy set.

Now of course the proability dist. needs to fulfill something in order for it to be a "correlated *equilibrium*": 

if for all players $i$ and all strategies $s_i,s'_i \in S_i$

i.e. if we take any player $i$ and any strategy $s_i$: 

$\sum_{S_{-i}} p(s_i,s_{-i})u_i(s_i,s_{-i})$ $\geq$ $\sum_{S_{-i}} p(s_i,s_{-i})u_i(s\'\_i,s_{-i})$

What this silly little thing means is, if I, player $i$, am given this strategy $s\_i$ by the coordinator,I have no reason to change my strategy to some $s'\_i$ as my EXPECTED PAYOFF by playing $s\_i$ (which is what $\sum_{S_{-i}} p(s_i,s_{-i})u_i(s_i,s_{-i})$ is btw), cannot be increased any more by, say, choosing to disregard the coordinator and being like, "I'll play $s'_i$ instead".

> How we are calculating expected payoff is by taking all the different $s_{-i}$'s that are possible and then calculating payoffs for each of them, and then i calculate my net expected payoff by multiplying each of the payoffs ( $u_i(s_i,s_{-i})$ ) with the probability of selecting that particular strat. vector by the coordinator ( $p(s_i,s_{-i})$ ) and summing them all up (for all the different $s_{-i}$'s).




## Look...
See now that Nash Equilibria are a special case of correlated equilibria. In essence, a Nash equilibria is a correlated equiilibria but the probabilities of each of the strategy vectors are a product of the probabilities of the indivdial players (based on each of their individual mixed strategies)
